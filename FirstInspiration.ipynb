{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mitbih_test.csv', 'mitbih_train.csv', 'ptbdb_abnormal.csv', 'ptbdb_normal.csv']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 109446 entries, 0 to 21891\n",
      "Columns: 188 entries, 0 to 187\n",
      "dtypes: float64(188)\n",
      "memory usage: 157.8 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SplendidUnivers\\Miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1005 18:01:14.572731 10752 deprecation_wrapper.py:119] From C:\\Users\\SplendidUnivers\\Miniconda3\\envs\\test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (109150, 187, 1)\n",
      "y_train (109150,)\n",
      "X_test (4000, 187, 1)\n",
      "y_test (4000,)\n",
      "X_train (109150, 187, 1)\n",
      "y_train (109150, 5)\n",
      "X_test (4000, 187, 1)\n",
      "y_test (4000, 5)\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 187, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 183, 32)      192         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 183, 32)      5152        conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 183, 32)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 183, 32)      5152        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 183, 32)      0           conv1d_3[0][0]                   \n",
      "                                                                 conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 183, 32)      0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 90, 32)       0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 90, 32)       5152        max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 90, 32)       0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 90, 32)       5152        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 90, 32)       0           conv1d_7[0][0]                   \n",
      "                                                                 max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 90, 32)       0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 43, 32)       0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 43, 32)       5152        max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 43, 32)       0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 43, 32)       5152        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 43, 32)       0           conv1d_9[0][0]                   \n",
      "                                                                 max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 43, 32)       0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 20, 32)       0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 20, 32)       5152        max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 20, 32)       0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 20, 32)       5152        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 20, 32)       0           conv1d_11[0][0]                  \n",
      "                                                                 max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 20, 32)       0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 8, 32)        0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 256)          0           max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           8224        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           1056        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 5)            165         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "softmax_1 (Softmax)             (None, 5)            0           dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 50,853\n",
      "Trainable params: 50,853\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1005 18:01:16.942234 10752 deprecation_wrapper.py:119] From C:\\Users\\SplendidUnivers\\Miniconda3\\envs\\test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 109150 samples, validate on 4000 samples\n",
      "Epoch 1/75\n",
      " - 70s - loss: 0.3795 - accuracy: 0.8863 - val_loss: 0.7606 - val_accuracy: 0.7452\n",
      "Epoch 2/75\n",
      " - 69s - loss: 0.1462 - accuracy: 0.9601 - val_loss: 0.6884 - val_accuracy: 0.8215\n",
      "Epoch 3/75\n",
      " - 69s - loss: 0.1049 - accuracy: 0.9712 - val_loss: 0.5064 - val_accuracy: 0.8490\n",
      "Epoch 4/75\n",
      " - 71s - loss: 0.0860 - accuracy: 0.9759 - val_loss: 0.5444 - val_accuracy: 0.8508\n",
      "Epoch 5/75\n",
      " - 69s - loss: 0.0727 - accuracy: 0.9788 - val_loss: 0.3970 - val_accuracy: 0.8802\n",
      "Epoch 6/75\n",
      " - 69s - loss: 0.0660 - accuracy: 0.9809 - val_loss: 0.4230 - val_accuracy: 0.8810\n",
      "Epoch 7/75\n",
      " - 69s - loss: 0.0598 - accuracy: 0.9821 - val_loss: 0.4495 - val_accuracy: 0.8610\n",
      "Epoch 8/75\n",
      " - 69s - loss: 0.0570 - accuracy: 0.9828 - val_loss: 0.3872 - val_accuracy: 0.8873\n",
      "Epoch 9/75\n",
      " - 70s - loss: 0.0511 - accuracy: 0.9846 - val_loss: 0.3145 - val_accuracy: 0.9060\n",
      "Epoch 10/75\n",
      " - 70s - loss: 0.0473 - accuracy: 0.9856 - val_loss: 0.2611 - val_accuracy: 0.9162\n",
      "Epoch 11/75\n",
      " - 68s - loss: 0.0446 - accuracy: 0.9863 - val_loss: 0.2822 - val_accuracy: 0.9183\n",
      "Epoch 12/75\n",
      " - 68s - loss: 0.0434 - accuracy: 0.9865 - val_loss: 0.2814 - val_accuracy: 0.9193\n",
      "Epoch 13/75\n",
      " - 68s - loss: 0.0396 - accuracy: 0.9875 - val_loss: 0.2738 - val_accuracy: 0.9183\n",
      "Epoch 14/75\n",
      " - 68s - loss: 0.0377 - accuracy: 0.9881 - val_loss: 0.2706 - val_accuracy: 0.9290\n",
      "Epoch 15/75\n",
      " - 69s - loss: 0.0370 - accuracy: 0.9884 - val_loss: 0.3431 - val_accuracy: 0.8975\n",
      "Epoch 16/75\n",
      " - 68s - loss: 0.0346 - accuracy: 0.9890 - val_loss: 0.2036 - val_accuracy: 0.9370\n",
      "Epoch 17/75\n",
      " - 69s - loss: 0.0326 - accuracy: 0.9897 - val_loss: 0.2545 - val_accuracy: 0.9302\n",
      "Epoch 18/75\n",
      " - 68s - loss: 0.0320 - accuracy: 0.9898 - val_loss: 0.2537 - val_accuracy: 0.9143\n",
      "Epoch 19/75\n",
      " - 69s - loss: 0.0284 - accuracy: 0.9906 - val_loss: 0.1870 - val_accuracy: 0.9395\n",
      "Epoch 20/75\n",
      " - 69s - loss: 0.0308 - accuracy: 0.9899 - val_loss: 0.2776 - val_accuracy: 0.9243\n",
      "Epoch 21/75\n",
      " - 69s - loss: 0.0264 - accuracy: 0.9914 - val_loss: 0.2070 - val_accuracy: 0.9405\n",
      "Epoch 22/75\n",
      " - 69s - loss: 0.0262 - accuracy: 0.9913 - val_loss: 0.3174 - val_accuracy: 0.9143\n",
      "Epoch 23/75\n",
      " - 68s - loss: 0.0251 - accuracy: 0.9915 - val_loss: 0.3186 - val_accuracy: 0.9250\n",
      "Epoch 24/75\n",
      " - 68s - loss: 0.0244 - accuracy: 0.9919 - val_loss: 0.3056 - val_accuracy: 0.9212\n",
      "Epoch 25/75\n",
      " - 68s - loss: 0.0226 - accuracy: 0.9923 - val_loss: 0.2922 - val_accuracy: 0.9202\n",
      "Epoch 26/75\n",
      " - 68s - loss: 0.0217 - accuracy: 0.9928 - val_loss: 0.1944 - val_accuracy: 0.9352\n",
      "Epoch 27/75\n",
      " - 69s - loss: 0.0208 - accuracy: 0.9931 - val_loss: 0.2703 - val_accuracy: 0.9155\n",
      "Epoch 28/75\n",
      " - 71s - loss: 0.0205 - accuracy: 0.9933 - val_loss: 0.2380 - val_accuracy: 0.9250\n",
      "Epoch 29/75\n",
      " - 70s - loss: 0.0209 - accuracy: 0.9929 - val_loss: 0.2849 - val_accuracy: 0.9275\n",
      "Epoch 30/75\n",
      " - 70s - loss: 0.0189 - accuracy: 0.9935 - val_loss: 0.2384 - val_accuracy: 0.9310\n",
      "Epoch 31/75\n",
      " - 70s - loss: 0.0177 - accuracy: 0.9942 - val_loss: 0.2285 - val_accuracy: 0.9440\n",
      "Epoch 32/75\n",
      " - 69s - loss: 0.0171 - accuracy: 0.9944 - val_loss: 0.2092 - val_accuracy: 0.9420\n",
      "Epoch 33/75\n",
      " - 69s - loss: 0.0172 - accuracy: 0.9942 - val_loss: 0.2846 - val_accuracy: 0.9370\n",
      "Epoch 34/75\n",
      " - 70s - loss: 0.0169 - accuracy: 0.9941 - val_loss: 0.2585 - val_accuracy: 0.9390\n",
      "Epoch 35/75\n",
      " - 68s - loss: 0.0172 - accuracy: 0.9942 - val_loss: 0.2743 - val_accuracy: 0.9413\n",
      "Epoch 36/75\n",
      " - 69s - loss: 0.0138 - accuracy: 0.9952 - val_loss: 0.2710 - val_accuracy: 0.9360\n",
      "Epoch 37/75\n",
      " - 69s - loss: 0.0155 - accuracy: 0.9945 - val_loss: 0.2566 - val_accuracy: 0.9423\n",
      "Epoch 38/75\n",
      " - 68s - loss: 0.0146 - accuracy: 0.9949 - val_loss: 0.2668 - val_accuracy: 0.9423\n",
      "Epoch 39/75\n",
      " - 68s - loss: 0.0140 - accuracy: 0.9948 - val_loss: 0.3093 - val_accuracy: 0.9220\n",
      "Epoch 40/75\n",
      " - 68s - loss: 0.0147 - accuracy: 0.9947 - val_loss: 0.2844 - val_accuracy: 0.9342\n",
      "Epoch 41/75\n",
      " - 68s - loss: 0.0145 - accuracy: 0.9949 - val_loss: 0.2178 - val_accuracy: 0.9550\n",
      "Epoch 42/75\n",
      " - 68s - loss: 0.0142 - accuracy: 0.9950 - val_loss: 0.2757 - val_accuracy: 0.9367\n",
      "Epoch 43/75\n",
      " - 68s - loss: 0.0139 - accuracy: 0.9952 - val_loss: 0.2320 - val_accuracy: 0.9498\n",
      "Epoch 44/75\n",
      " - 69s - loss: 0.0130 - accuracy: 0.9955 - val_loss: 0.2878 - val_accuracy: 0.9312\n",
      "Epoch 45/75\n",
      " - 75s - loss: 0.0113 - accuracy: 0.9960 - val_loss: 0.3125 - val_accuracy: 0.9287\n",
      "Epoch 46/75\n",
      " - 75s - loss: 0.0123 - accuracy: 0.9955 - val_loss: 0.2785 - val_accuracy: 0.9405\n",
      "Epoch 47/75\n",
      " - 78s - loss: 0.0132 - accuracy: 0.9953 - val_loss: 0.2860 - val_accuracy: 0.9408\n",
      "Epoch 48/75\n",
      " - 76s - loss: 0.0130 - accuracy: 0.9955 - val_loss: 0.2796 - val_accuracy: 0.9315\n",
      "Epoch 49/75\n",
      " - 72s - loss: 0.0119 - accuracy: 0.9957 - val_loss: 0.3474 - val_accuracy: 0.9245\n",
      "Epoch 50/75\n",
      " - 73s - loss: 0.0102 - accuracy: 0.9966 - val_loss: 0.3173 - val_accuracy: 0.9283\n",
      "Epoch 51/75\n",
      " - 74s - loss: 0.0109 - accuracy: 0.9962 - val_loss: 0.4239 - val_accuracy: 0.9147\n",
      "Epoch 52/75\n",
      " - 73s - loss: 0.0113 - accuracy: 0.9960 - val_loss: 0.2211 - val_accuracy: 0.9517\n",
      "Epoch 53/75\n",
      " - 70s - loss: 0.0118 - accuracy: 0.9960 - val_loss: 0.2404 - val_accuracy: 0.9385\n",
      "Epoch 54/75\n",
      " - 68s - loss: 0.0113 - accuracy: 0.9962 - val_loss: 0.2060 - val_accuracy: 0.9550\n",
      "Epoch 55/75\n",
      " - 68s - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.2694 - val_accuracy: 0.9420\n",
      "Epoch 56/75\n",
      " - 73s - loss: 0.0102 - accuracy: 0.9966 - val_loss: 0.2971 - val_accuracy: 0.9438\n",
      "Epoch 57/75\n",
      " - 75s - loss: 0.0092 - accuracy: 0.9967 - val_loss: 0.2372 - val_accuracy: 0.9500\n",
      "Epoch 58/75\n",
      " - 67s - loss: 0.0114 - accuracy: 0.9962 - val_loss: 0.2925 - val_accuracy: 0.9360\n",
      "Epoch 59/75\n",
      " - 67s - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.3004 - val_accuracy: 0.9438\n",
      "Epoch 60/75\n",
      " - 67s - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.3401 - val_accuracy: 0.9308\n",
      "Epoch 61/75\n",
      " - 67s - loss: 0.0090 - accuracy: 0.9965 - val_loss: 0.2839 - val_accuracy: 0.9435\n",
      "Epoch 62/75\n",
      " - 68s - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.4458 - val_accuracy: 0.9208\n",
      "Epoch 63/75\n",
      " - 68s - loss: 0.0113 - accuracy: 0.9960 - val_loss: 0.3511 - val_accuracy: 0.9362\n",
      "Epoch 64/75\n",
      " - 68s - loss: 0.0109 - accuracy: 0.9962 - val_loss: 0.3641 - val_accuracy: 0.9345\n",
      "Epoch 65/75\n",
      " - 69s - loss: 0.0094 - accuracy: 0.9967 - val_loss: 0.3193 - val_accuracy: 0.9440\n",
      "Epoch 66/75\n",
      " - 69s - loss: 0.0094 - accuracy: 0.9966 - val_loss: 0.3274 - val_accuracy: 0.9317\n",
      "Epoch 67/75\n",
      " - 68s - loss: 0.0098 - accuracy: 0.9966 - val_loss: 0.2764 - val_accuracy: 0.9435\n",
      "Epoch 68/75\n",
      " - 69s - loss: 0.0092 - accuracy: 0.9967 - val_loss: 0.3155 - val_accuracy: 0.9410\n",
      "Epoch 69/75\n",
      " - 68s - loss: 0.0130 - accuracy: 0.9955 - val_loss: 0.3672 - val_accuracy: 0.9362\n",
      "Epoch 70/75\n",
      " - 68s - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.2593 - val_accuracy: 0.9500\n",
      "Epoch 71/75\n",
      " - 68s - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.2115 - val_accuracy: 0.9538\n",
      "Epoch 72/75\n",
      " - 69s - loss: 0.0095 - accuracy: 0.9967 - val_loss: 0.3224 - val_accuracy: 0.9405\n",
      "Epoch 73/75\n",
      " - 67s - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.4063 - val_accuracy: 0.9337\n",
      "Epoch 74/75\n",
      " - 67s - loss: 0.0080 - accuracy: 0.9973 - val_loss: 0.2964 - val_accuracy: 0.9480\n",
      "Epoch 75/75\n",
      " - 69s - loss: 0.0098 - accuracy: 0.9966 - val_loss: 0.3200 - val_accuracy: 0.9362\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.99      0.89       800\n",
      "           1       1.00      0.82      0.90       800\n",
      "           2       0.95      0.96      0.95       800\n",
      "           3       0.99      0.92      0.95       800\n",
      "           4       1.00      0.99      0.99       800\n",
      "\n",
      "    accuracy                           0.94      4000\n",
      "   macro avg       0.95      0.94      0.94      4000\n",
      "weighted avg       0.95      0.94      0.94      4000\n",
      "\n",
      "ranking-based average precision : 0.967\n",
      "Ranking loss : 0.019\n",
      "Coverage_error : 1.076\n",
      "Confusion matrix, without normalization\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, label_ranking_average_precision_score, label_ranking_loss, coverage_error \n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from scipy.signal import resample\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Conv1D, MaxPooling1D, Softmax, Add, Flatten, Activation# , Dropout\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"C:/Users/SplendidUnivers/Desktop/input\"))\n",
    "\n",
    "df = pd.read_csv(\"C:/Users/SplendidUnivers/Desktop/input/mitbih_train.csv\", header=None)\n",
    "df2 = pd.read_csv(\"C:/Users/SplendidUnivers/Desktop/input/mitbih_test.csv\", header=None)\n",
    "df = pd.concat([df, df2], axis=0)\n",
    "\n",
    "df.head()\n",
    "\n",
    "df.info()\n",
    "\n",
    "df[187].value_counts()\n",
    "\n",
    "M = df.values\n",
    "X = M[:, :-1]\n",
    "y = M[:, -1].astype(int)\n",
    "del df\n",
    "del df2\n",
    "del M\n",
    "\n",
    "#Visualisation\n",
    "C0 = np.argwhere(y == 0).flatten()\n",
    "C1 = np.argwhere(y == 1).flatten()\n",
    "C2 = np.argwhere(y == 2).flatten()\n",
    "C3 = np.argwhere(y == 3).flatten()\n",
    "C4 = np.argwhere(y == 4).flatten()\n",
    "x = np.arange(0, 187)*8/1000\n",
    "\n",
    "plt.figure(figsize=(20,12))\n",
    "plt.plot(x, X[C0, :][0], label=\"Cat. N\")\n",
    "plt.plot(x, X[C1, :][0], label=\"Cat. S\")\n",
    "plt.plot(x, X[C2, :][0], label=\"Cat. V\")\n",
    "plt.plot(x, X[C3, :][0], label=\"Cat. F\")\n",
    "plt.plot(x, X[C4, :][0], label=\"Cat. Q\")\n",
    "plt.legend()\n",
    "plt.title(\"1-beat ECG for every category\", fontsize=20)\n",
    "plt.ylabel(\"Amplitude\", fontsize=15)\n",
    "plt.xlabel(\"Time (ms)\", fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "#data augmentation\n",
    "def stretch(x):\n",
    "    l = int(187 * (1 + (random.random()-0.5)/3))\n",
    "    y = resample(x, l)\n",
    "    if l < 187:\n",
    "        y_ = np.zeros(shape=(187, ))\n",
    "        y_[:l] = y\n",
    "    else:\n",
    "        y_ = y[:187]\n",
    "    return y_\n",
    "\n",
    "def amplify(x):\n",
    "    alpha = (random.random()-0.5)\n",
    "    factor = -alpha*x + (1+alpha)\n",
    "    return x*factor\n",
    "\n",
    "def augment(x):\n",
    "    result = np.zeros(shape= (4, 187))\n",
    "    for i in range(3):\n",
    "        if random.random() < 0.33:\n",
    "            new_y = stretch(x)\n",
    "        elif random.random() < 0.66:\n",
    "            new_y = amplify(x)\n",
    "        else:\n",
    "            new_y = stretch(x)\n",
    "            new_y = amplify(new_y)\n",
    "        result[i, :] = new_y\n",
    "    return result\n",
    "plt.plot(X[0, :])\n",
    "plt.plot(amplify(X[0, :]))\n",
    "plt.plot(stretch(X[0, :]))\n",
    "plt.show()\n",
    "\n",
    "#data storage into results and classes\n",
    "result = np.apply_along_axis(augment, axis=1, arr=X[C3]).reshape(-1, 187)\n",
    "classe = np.ones(shape=(result.shape[0],), dtype=int)*3\n",
    "X = np.vstack([X, result])\n",
    "y = np.hstack([y, classe])\n",
    "\n",
    "\n",
    "#Split into train and test datasets\n",
    "subC0 = np.random.choice(C0, 800)\n",
    "subC1 = np.random.choice(C1, 800)\n",
    "subC2 = np.random.choice(C2, 800)\n",
    "subC3 = np.random.choice(C3, 800)\n",
    "subC4 = np.random.choice(C4, 800)\n",
    "X_test = np.vstack([X[subC0], X[subC1], X[subC2], X[subC3], X[subC4]])\n",
    "y_test = np.hstack([y[subC0], y[subC1], y[subC2], y[subC3], y[subC4]])\n",
    "\n",
    "X_train = np.delete(X, [subC0, subC1, subC2, subC3, subC4], axis=0)\n",
    "y_train = np.delete(y, [subC0, subC1, subC2, subC3, subC4], axis=0)\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=0)\n",
    "X_test, y_test = shuffle(X_test, y_test, random_state=0)\n",
    "\n",
    "del X\n",
    "del y\n",
    "X_train = np.expand_dims(X_train, 2)\n",
    "X_test = np.expand_dims(X_test, 2)\n",
    "\n",
    "#Shape\n",
    "print(\"X_train\", X_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"X_test\", X_test.shape)\n",
    "print(\"y_test\", y_test.shape)\n",
    "\n",
    "#apply onehotencoder to reshape the datasets\n",
    "ohe = OneHotEncoder()\n",
    "y_train = ohe.fit_transform(y_train.reshape(-1,1))\n",
    "y_test = ohe.transform(y_test.reshape(-1,1))\n",
    "\n",
    "print(\"X_train\", X_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"X_test\", X_test.shape)\n",
    "print(\"y_test\", y_test.shape)\n",
    "\n",
    "\n",
    "#the Model\n",
    "n_obs, feature, depth = X_train.shape\n",
    "batch_size = 500\n",
    "K.clear_session()\n",
    "\n",
    "inp = Input(shape=(feature, depth))\n",
    "C = Conv1D(filters=32, kernel_size=5, strides=1)(inp)\n",
    "\n",
    "C11 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(C)\n",
    "A11 = Activation(\"relu\")(C11)\n",
    "C12 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A11)\n",
    "S11 = Add()([C12, C])\n",
    "A12 = Activation(\"relu\")(S11)\n",
    "M11 = MaxPooling1D(pool_size=5, strides=2)(A12)\n",
    "\n",
    "\n",
    "C21 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(M11)\n",
    "A21 = Activation(\"relu\")(C21)\n",
    "C22 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A21)\n",
    "S21 = Add()([C22, M11])\n",
    "A22 = Activation(\"relu\")(S11)\n",
    "M21 = MaxPooling1D(pool_size=5, strides=2)(A22)\n",
    "\n",
    "\n",
    "C31 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(M21)\n",
    "A31 = Activation(\"relu\")(C31)\n",
    "C32 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A31)\n",
    "S31 = Add()([C32, M21])\n",
    "A32 = Activation(\"relu\")(S31)\n",
    "M31 = MaxPooling1D(pool_size=5, strides=2)(A32)\n",
    "\n",
    "\n",
    "C41 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(M31)\n",
    "A41 = Activation(\"relu\")(C41)\n",
    "C42 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A41)\n",
    "S41 = Add()([C42, M31])\n",
    "A42 = Activation(\"relu\")(S41)\n",
    "M41 = MaxPooling1D(pool_size=5, strides=2)(A42)\n",
    "\n",
    "\n",
    "C51 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(M41)\n",
    "A51 = Activation(\"relu\")(C51)\n",
    "C52 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A51)\n",
    "S51 = Add()([C52, M41])\n",
    "A52 = Activation(\"relu\")(S51)\n",
    "M51 = MaxPooling1D(pool_size=5, strides=2)(A52)\n",
    "\n",
    "F1 = Flatten()(M51)\n",
    "\n",
    "D1 = Dense(32)(F1)\n",
    "A6 = Activation(\"relu\")(D1)\n",
    "D2 = Dense(32)(A6)\n",
    "D3 = Dense(5)(D2)\n",
    "A7 = Softmax()(D3)\n",
    "\n",
    "model = Model(inputs=inp, outputs=A7)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#compiling and fitting the model\n",
    "def exp_decay(epoch):\n",
    "    initial_lrate = 0.001\n",
    "    k = 0.75\n",
    "    t = n_obs//(10000 * batch_size)  # every epoch we do n_obs/batch_size iteration\n",
    "    lrate = initial_lrate * math.exp(-k*t)\n",
    "    return lrate\n",
    "\n",
    "lrate = LearningRateScheduler(exp_decay)\n",
    "adam = Adam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=75, \n",
    "                    batch_size=batch_size, \n",
    "                    verbose=2, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    callbacks=[lrate])\n",
    "\n",
    "#prediction\n",
    "y_pred = model.predict(X_test, batch_size=1000)\n",
    "print(classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1)))\n",
    "print(\"ranking-based average precision : {:.3f}\".format(label_ranking_average_precision_score(y_test.todense(), y_pred)))\n",
    "print(\"Ranking loss : {:.3f}\".format(label_ranking_loss(y_test.todense(), y_pred)))\n",
    "print(\"Coverage_error : {:.3f}\".format(coverage_error(y_test.todense(), y_pred)))\n",
    "\n",
    "#confusion matrix\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=(10, 10))\n",
    "plot_confusion_matrix(cnf_matrix, classes=['N', 'S', 'V', 'F', 'Q'],\n",
    "                      title='Confusion matrix, without normalization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=(10, 10))\n",
    "plot_confusion_matrix(cnf_matrix, classes=['N', 'S', 'V', 'F', 'Q'],\n",
    "                      title='Confusion matrix, without normalization')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ranking-based average precision : 0.967\n",
      "Ranking loss : 0.019\n",
      "Coverage_error : 1.076\n"
     ]
    }
   ],
   "source": [
    "print(\"ranking-based average precision : {:.3f}\".format(label_ranking_average_precision_score(y_test.todense(), y_pred)))\n",
    "print(\"Ranking loss : {:.3f}\".format(label_ranking_loss(y_test.todense(), y_pred)))\n",
    "print(\"Coverage_error : {:.3f}\".format(coverage_error(y_test.todense(), y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
